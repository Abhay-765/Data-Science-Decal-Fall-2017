{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exciting Stuff\n",
    "\n",
    "In this notebook you will solve a problem that was posed as follows for CS189 Spring 2017 (with minor modifications): \n",
    "\n",
    "\"Jordan is planning the frat party of the semester. Heâ€™s completely stocked up on Franzia. Unfortunately, the\n",
    "labels for 497 boxes (test set) have been scratched off, and he needs to quickly find out which boxes contain\n",
    "Red wine (label 1) and White wine (label 0). Fortunately, for him the boxes still have their Nutrition Facts\n",
    "(features) intact and detail the chemical composition of the wine inside the boxes (the description of these\n",
    "features and the features themselves are provided in data.mat). He also has 6,000 boxes with Nutrition\n",
    "Facts and labels intact (train set). Help Jordan figure out what the labels should be for the 497 mystery boxes.\"\n",
    "\n",
    "Dataset creds: Jonathan Shewchuk's CS189 Spring 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat as loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Functions\n",
    "Fill these in so that we can perform training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(X, w):\n",
    "    \"\"\"\n",
    "    Compute the elementwise sigmoid of the product Xw\n",
    "    Data in X should be rows, weights are a column. \n",
    "    returns: s(Xw)\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-np.dot(X, w)))\n",
    "\n",
    "def gradient(X, y, w, onept, lamb=0):\n",
    "    \"\"\"\n",
    "    Compute gradient of regularized loss function. \n",
    "    Accomodate for if X is just one data point. \n",
    "    returns: gradient (should match dimensions of w)\n",
    "    \"\"\"\n",
    "    if onept:\n",
    "        return 2 * lamb * w - ((y - sigmoid(X, w)) * X).reshape(w.size, 1)\n",
    "    return 2 * lamb * w - np.dot(X.T, y - sigmoid(X, w)) / y.size\n",
    "\n",
    "def loss(X, y, w, lamb=0):\n",
    "    \"\"\"\n",
    "    Compute average loss for the data in X, labels in y, params w\n",
    "    returns: scalar value of average loss\n",
    "    \"\"\"\n",
    "    sumcost = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        sumcost += y[i] * np.log(sigmoid(X[i], w)) + (1 - y[i]) * np.log(1 - sigmoid(X[i], w))\n",
    "    return lamb * np.linalg.norm(w) ** 2 - sumcost / y.size\n",
    "    \n",
    "def accuracy(X, y, w):\n",
    "    \"\"\"\n",
    "    Compute accuracy for data in X, labels in y, params w\n",
    "    returns: scalar value of average accuracy\n",
    "    \"\"\"\n",
    "    results = np.round(sigmoid(X, w))\n",
    "    score = sum([results[i] == y[i] for i in range(y.size)]) / y.size\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data\n",
    "This procedure uses loading a .mat file. The returned object is a dictionary that has numpy arrays as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['description', 'X', '__header__', 'X_test', '__version__', '__globals__', 'y'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winedata = loadmat('./data.mat')\n",
    "winedata.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "Let's add a bias feature to improve the capacity of our model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wineTrain = winedata['X'] \n",
    "wineLabels = winedata['y']\n",
    "\n",
    "wineTrain = np.concatenate([wineTrain, np.ones((wineTrain.shape[0], 1))], axis=1) # make sure you understand this line\n",
    "wineTrain.shape \n",
    "\n",
    "weights = np.random.rand(wineTrain.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent\n",
    "- Create an empty list of loss values which we will fill and visualize.\n",
    "- Perform training using the entire dataset for gradient calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I know it was quick in the lecture, but training is basically just a loop. \n",
    "# Loop over something, change the weights in every iteration of the loop. \n",
    "# Batch gradient descent means using *all* of the data points for every gradient calculation. \n",
    "# Pick an epsilon as a step rate (don't make it too big)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The Loss \n",
    "- Plot loss values with respect to every training step. \n",
    "- How can you explain the shape that this graph takes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use matplotlib \n",
    "# just dots will be fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Training Exercise with SGD\n",
    "- Training with respect to only one point instead of the whole dataset. \n",
    "- Plot the losses. Why does the graph take the shape that it does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's the difference between batch and SGD? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
